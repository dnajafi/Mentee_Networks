Most of our code base was adapted from the Multilary Perceptron tutorial found at http://deeplearning.net/tutorial/mlp.html as well as the Logistic Regression tutorial found at http://deeplearning.net/tutorial/logreg.html  

mentoring.py contains code  that builds a 2-hidden layer MLP (the mentor with 100 hidden units per layer) and a 1-hidden layer MLP (the mentee with 100 hidden units per layer).

logistic_sgd.py contains code for logistic regression as well as our implementation of temperature softmax.

In order to change the number of epochs or the number of hidden units in the MLPs refer to line 330 in mentoring.py.

To run a particular dataset (as a pickle file), enter it as the second argument on the command line. Datasets can be found at: https://drive.google.com/open?id=0BxjPi5hQJFuHYkJFem9xYnhDSms


To change the alpha, beta, or gamma parameters in the mentee's cost function, please refer to line 418 in mentoring.py

NOTE: Our code is written using Theano so this must be installed first! Please refer to http://deeplearning.net/software/theano/install.html in order to install Theano.


Instructions to run (in a Unix environment):

1. Navigate to the directory that contains mentoring.py, logistic_sgd.py, and the dataset used for training, validation, and testing.

2. In the command line type 'python mentoring.py dataset' where dataset is a pickle file containing whatever data you'd like to train, validate, and test on. Then press Enter to run.

3. The program will first train/test a mentor for however many epochs you prefer (refer to above to change the number of epochs) and then will train/test a mentee for the same number of epochs.


